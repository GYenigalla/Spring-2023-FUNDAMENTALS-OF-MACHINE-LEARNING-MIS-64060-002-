---
title: "FML ASSIGNMENT 2"
author: "Gayathri Yenigalla"
date: "2023-02-19"
output:
  word_document: default
  html_document: default
---
```{r}
# loading packages 
library(class)
library(dplyr)
library(caret)
library(tinytex)

#importing dataset.

My_Bank <- read.csv("C:/Users/gaya3/Downloads/Universalbank.csv")

#deleting unnecessary columns, such as ID and Zip code
My_Bank$ID<-NULL
My_Bank$ZIP.Code<-NULL
```


```{r}
#converting to a variable factor
My_Bank$Personal.Loan=as.factor(My_Bank$Personal.Loan)
```

#running is.na command to check if there are any NA values
```{r}
sum(is.na(My_Bank))
```

#converting education into character
```{r}
My_Bank$Education=as.character(My_Bank$Education)
```

#Creating dummy  variables
```{r}
education.1 <- ifelse(My_Bank$Education==1 ,1,0)

education.2 <- ifelse(My_Bank$Education==2 ,1,0)

education.3 <- ifelse(My_Bank$Education==3 ,1,0)

UB.2<-data.frame(Age=My_Bank$Age,Experience=My_Bank$Experience,Income=My_Bank$Income,Family=My_Bank$Family,CCAvg=My_Bank$CCAvg, education.1=education.1,education.2=education.2,education.3=education.3,Personal.Loan=My_Bank$Personal.Loan,Mortgage=My_Bank$Mortgage,Securities.Account=My_Bank$Securities.Account,CD.Account=My_Bank$CD.Account,Online=My_Bank$Online,CreditCard=My_Bank$CreditCard)
```

#setting up testdata
```{r}
UBtest.1<-data.frame(Age=40,Experience=10,Income=84,Family=2,CCAvg=2,education.1=0,education.2=1,education.3=0,Mortgage=0,Securities.Account=0,CD.Account=0,Online=1,CreditCard=1)
```

#separating training and test sets of data
```{r}
set.seed(130)
UB.dummy<- createDataPartition(UB.2$Personal.Loan,p=.6,list=FALSE,times=1)
train1.ub <- UB.2[UB.dummy, ]
valid1.ub<- UB.2[-UB.dummy, ]
```

#Normalization
```{r}
UB.norm=preProcess(train1.ub[,-(6:9)],method=c("center","scale"))
trainNorm.ub =predict(UB.norm,train1.ub)
validNorm.ub =predict(UB.norm,valid1.ub)
testNorm.ub =predict(UB.norm,UBtest.1)
```

#printing knn algorithm
```{r}
predicttrain.ub<-trainNorm.ub[,-9]
trainsample.ub<-trainNorm.ub[,9]
predictvalid.ub<-validNorm.ub[,-9]
validsample.ub<-validNorm.ub[,9]
```

```{r}
predict.ub<-knn(predicttrain.ub, testNorm.ub, cl=trainsample.ub,k=1)
predict.ub
```

```{r}
predict.uvb <- knn(predicttrain.ub, predictvalid.ub, cl=trainsample.ub, k=1)
```

#The customer has rejected the loan offer. When the k value is 0, it is decided.

#printing ou the best value of k
```{r}
set.seed(130)
grid.ub<-expand.grid(k=seq(1:30))                  
model.ub<-train(Personal.Loan~.,data=trainNorm.ub,method="knn",tuneGrid=grid.ub)
model.ub

value.k<-model.ub$bestTune[[1]]
```

```{r}
#confusion matrix - validation dataset
confusionMatrix(predict.uvb,validsample.ub)
```

```{r}
#50:30:20 Repartition
data.part.new <- createDataPartition(UB.2$Personal.Loan,p=0.5, list = F)
Train.new <- UB.2[data.part.new,]
Train.db.new <- UB.2[-data.part.new,]

data.part.new.1 <- createDataPartition(Train.db.new$Personal.Loan, p=0.6, list = F)
validate.new <- Train.db.new[data.part.new.1,]
test.new <- Train.db.new[-data.part.new.1,]
```

#Normalization
```{r}
norm.new <- preProcess(Train.new[,-(6:9)], method=c("center","scale"))
Train.new.p <- predict(norm.new, Train.new)
Validate.new.p <- predict(norm.new, validate.new)
Test.new.p <- predict(norm.new, test.new)
```

#predictors and labels
```{r}
train.pre <- Train.new.p[,-9]
validate.pre <- Validate.new.p[,-9]
test.pre <- Test.new.p[,-9]
```

```{r}
train.l <- Train.new.p[,9]
validate.l <- Validate.new.p[,9]
test.l <- Test.new.p[,9]
```

#knn
```{r}
knn.t <- knn(train.pre,train.pre,cl= train.l, k=value.k)

knn.v <- knn(train.pre,validate.pre,cl=train.l, k=value.k)

knn.tes <- knn(train.pre,test.pre,cl=train.l, k=value.k)

confusionMatrix(knn.t,train.l)
confusionMatrix(knn.v,validate.l)
confusionMatrix(knn.tes,test.l) 

#accuracy for knn model = 0.961
#sensitivity for knn model = 0.9945 
#specificity for knn model = 0.6458  

```